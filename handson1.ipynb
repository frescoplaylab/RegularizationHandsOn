{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nF_5oOZ9OEaG"
   },
   "source": [
    "Welcome to the first handson!!!\n",
    "- In this handson you will be building an optimized network for binary classification.\n",
    "- You will learn how to incorporate regularization and dropout techniques in order to generalize the model's prediction.\n",
    "- Follow the instruction provided for cell to write the code in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivY_tF8yVKex"
   },
   "source": [
    "- The data is provided as file named 'blobs.csv'.\n",
    "- The data has two features feature1 and feature2 and one targer variable which is a binary value\n",
    "- Using pandas read the csv file and assign the resulting dataframe to variable 'df'   \n",
    "- for example if file name is 'xyz.csv' read file as **pd.read_csv('xyz.csv')**\n",
    "- Packages to import: **pandas** (to read csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0BHA1dAKyzw8"
   },
   "outputs": [],
   "source": [
    "###Sart code              \n",
    "              #import pandas \n",
    "df =          #create a dataframe named 'data' from 'blobs.csv' file\n",
    "###End code\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqCtS1D3Wi44"
   },
   "source": [
    "- Extract feature1 and feature2 values from dataframe 'df' and assign it to variable 'X'\n",
    "- Extract target variable 'traget' and assign it to variable 'y'.  \n",
    "Hint:\n",
    " - Use .values to exract values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IaRJ8HLLXpuK"
   },
   "outputs": [],
   "source": [
    "###Start code\n",
    "X =                                      #extract feature1 and feature2 values\n",
    "y =                                      #extract target values\n",
    "###End code\n",
    "assert X.shape == (5000, 2)\n",
    "assert y.shape == (5000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the below cell to visualize the data in x-y plane. (visualization code has been written for you)\n",
    "- The blue spots corresponds to target value 0 and green spots corresponds to target value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OLSGMjm0VGkJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "colors=['blue','green']\n",
    "cmap = matplotlib.colors.ListedColormap(colors)\n",
    "#Plot the figure\n",
    "plt.figure()\n",
    "plt.title('Non-linearly separable classes')\n",
    "plt.scatter(X[:,0], X[:,1], c=y,\n",
    "           marker= 'o', s=50,cmap=cmap,alpha = 0.5 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to feed the network the input has to be of **shape (number of features, number of samples)** and target should be of shape **(1, number of samples)**\n",
    "- Transpose X and assign it to variable 'X_data'\n",
    "- reshape y to have shape (1, number of samples) and assign to variable 'y_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XchlAZPwHpMk"
   },
   "outputs": [],
   "source": [
    "###Start code\n",
    "X_data = \n",
    "y_data = \n",
    "###End code\n",
    "\n",
    "assert X_data.shape == (2, 5000)\n",
    "assert y_data.shape == (1, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network dimension to have two input features, two hidden layers with 25 nodes each, one output node at final layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "t_dEEaJykLSa"
   },
   "outputs": [],
   "source": [
    "layer_dims = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow package as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                          #import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named placeholders to return two placeholders one for input data as A_0 and one for output data as Y.\n",
    "- Set the datatype of placeholders as float64\n",
    "- parameters - num_features\n",
    "- Returns - A_0 with shape (num_feature, None) and Y with shape(1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4kp4_9kS58CT"
   },
   "outputs": [],
   "source": [
    "def placeholders(num_features):\n",
    "    A_0 = \n",
    "    Y = \n",
    "    return A_0,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function named initialize_parameters_deep() to initialize weights and bias for each layer\n",
    "- Use tf.get_variable to initialise weights and bias, set datatype as float64\n",
    "- Make sure you are using xavier initialization for weigths and initialize bias to zeros\n",
    "- Parameters - layer_dims\n",
    "- Returns - dictionary of weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "W3l_vyXVkrlw"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    tf.set_random_seed(1)\n",
    "    L = len(layer_dims)\n",
    "    parameters = {}\n",
    "    for l in range(1,L):\n",
    "        parameters['W' + str(l)] = \n",
    "                                   \n",
    "        parameters['b' + str(l)] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functon named linear_forward_prop() to define forward propagation for a given layer.\n",
    "- parameters: A_prev(output from previous layer), W(weigth matrix of current layer), b(bias vector for current layer),activation(type of activation to be used for out of current layer)  \n",
    "- returns: A(output from the current layer)\n",
    "- Use relu activation for hidden layers and for final output layer return the output unactivated i.e if activation is sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SKbSUt5g4toV"
   },
   "outputs": [],
   "source": [
    "def linear_forward_prop(A_prev,W,b, activation):\n",
    "    ###Start code\n",
    "    Z = \n",
    "    if activation == \"sigmoid\":\n",
    "        A =  \n",
    "    elif activation == \"relu\":\n",
    "        A =\n",
    "    ###End code\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward propagation for entire network as l_layer_forward()\n",
    "- Parameters: A_0(input data), parameters(dictionary of weights and bias), dropout (boolean)\n",
    "- returns: A(output from final layer)  \n",
    "If dropout = True, deactivate the layers's output with probability value equal to 0.8.  \n",
    "use tensoflow's droupout function to apply dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Cdks1w__k-Ei"
   },
   "outputs": [],
   "source": [
    "def l_layer_forwardProp(A_0, parameters, drop_out = False):\n",
    "    A = A_0\n",
    "    L = len(parameters)//2                               #number of layers\n",
    "    for l in range(1,L):                                 \n",
    "        A_prev = A\n",
    "        ###Start code\n",
    "        A =                                             #call linear_forward_prop to return the output from current layer\n",
    "        ###End code\n",
    "        if drop_out:                                    #check if dropout == True, if true apply dropout to current layer's output.\n",
    "            A =                                        # call tensoflow's droupout function to deactivate output A, set keep_prob = 0.8\n",
    "    A = linear_forward_prop(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\" )   # return output from final layer.\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the cost function\n",
    "- parameters:\n",
    "  - Z_final: output fro final layer\n",
    "  - Y: actual output\n",
    "  - parameters: dictionary of weigths and bias\n",
    "  - regularization : boolean\n",
    "  - lambd: regularization parameter\n",
    "- First define the original cost using tensoflow's sigmoid_cross_entropy function\n",
    "- If **regularization == True** add regularization term to original cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_cost(Z_final, Y , parameters, regularization = False, lambd = 0):\n",
    "    #define original cost\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z_final,labels=Y)\n",
    "    if regularization:\n",
    "        #initialize regularization term to zero\n",
    "        reg_term = 0                               \n",
    "        L = len(parameters)//2                     \n",
    "        for l in range(1,L+1):\n",
    "            #use tensorflow's l2 regularization to calculate regularization term for each later and\n",
    "            #sum it up to previous layer's regularization term\n",
    "            \n",
    "            ###Start code\n",
    "            reg_term += \n",
    "        \n",
    "        #multiply lambd/2 to reg_term to add it to original cost\n",
    "        cost += \n",
    "        ##End code\n",
    "    return tf.reduce_mean(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define the model to train the network\n",
    "- parameters:\n",
    "  - X_train, Y_train: input and target data\n",
    "  - layer_dims: network configuration\n",
    "  - learning_rate\n",
    "  - num_iter: number of epoches\n",
    "  - regularization (boolean): If true apply regularization\n",
    "  - lambd: regularization parameter ($\\lambda$)\n",
    "  - dropout (boolean): if true apply dropout\n",
    "- return: dictionary of trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HLZ_K8nNopoH"
   },
   "outputs": [],
   "source": [
    "def deep_net(X_train,Y_train, layer_dims, learning_rate, num_iter, regularization = False, lambd = 0, drop_out = False):\n",
    "    tf.reset_default_graph()                \n",
    "    num_features = layer_dims[0]\n",
    "    ###Start code\n",
    "    A_0, Y =                      #call placeholder function to initialize placeholders A_0 and Y\n",
    "    parameters =                  #Initialse Weights and bias using initialize_parameters_deep() with layer_dims as parameters  \n",
    "    Z_final =                     #call the function l_layer_forwardProp() to define the final output\n",
    "    \n",
    "    # call final_cost() function to return the cost that has to be minimized during gradient descent\n",
    "    cost = \n",
    "    \n",
    "    #call tensorflow's gradient descent optimizer function with minimize cost  \n",
    "    train_net =   \n",
    "    #End code\n",
    "    init = tf.global_variables_initializer()\n",
    "    costs = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(num_iter):\n",
    "            _,c = sess.run([train_net, cost], feed_dict={A_0: X_train, Y: Y_train})\n",
    "            if i % 100 == 0:\n",
    "                costs.append(c)\n",
    "            if i % 1000 == 0:\n",
    "                print(c)\n",
    "        with open('output.txt', 'w') as file:\n",
    "            file.write(\"cost = %f \"  % costs[-1])\n",
    "        plt.ylim(min(costs)+0.1 ,max(costs), 4, 0.01)\n",
    "        plt.xlabel(\"epoches per 100\")\n",
    "        plt.ylabel(\"cost\")\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "        params = sess.run(parameters)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to define the method to predict outputof the model for given input and parameters.The code has been written for you\n",
    "Note that we are not applying droupout during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(A_0, parameters):\n",
    "    with tf.Session() as sess:\n",
    "        Z = l_layer_forwardProp(A_0, parameters, drop_out= False)\n",
    "        A = sess.run(tf.round(tf.sigmoid(Z)))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the below cell to define the method to plot the decision boundary.The code for visualization has been written for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_decision_boundary1( X, y, model):\n",
    "    plt.clf()\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1   \n",
    "    colors=['blue','green']\n",
    "    cmap = matplotlib.colors.ListedColormap(colors)   \n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    A = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    A = A.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, A, cmap=\"spring\")\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y, s=8,cmap=cmap)\n",
    "    plt.title(\"Decision Boundary for learning rate:\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with no dropout and regualrization,   \n",
    "assign **learning_rate = 0.01** and **num_iter = 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "B2qeMlAP3UcS"
   },
   "outputs": [],
   "source": [
    "###Start code\n",
    "parameters =\n",
    "##End code\n",
    "plot_decision_boundary1(X_data,y,lambda x: predict(x.T,parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are able to train the network and visualize the decision boundary you can see that model's prediction has defined the boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the model with regularization.  \n",
    "assign **learning_rate = 0.01, num_iter = 10000 , regularization = True, lambd = 0.02**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Start code\n",
    "parameters = \n",
    "###end code\n",
    "plot_decision_boundary1(X_data,y,lambda x: predict(x.T,parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with dropout  \n",
    "assign **learning_rate = 0.01, num_iter = 10000 , regularization = False, drop_out = True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uR2nLVZBPIPG"
   },
   "outputs": [],
   "source": [
    "##Start code\n",
    "parameters = \n",
    "###End code\n",
    "plot_decision_boundary1(X_data,y,lambda x: predict(x.T,parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "DNN_hands_on_solution.ipynb",
   "provenance": [
    {
     "file_id": "1i6MJxD7kd04W6ojetXVPsNUeA4qGg6Zq",
     "timestamp": 1525158878710
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
